# Advanced-Machine-Learning-Projects (incomplete)
Projects for the course Advanced Machine Learning. In this repository, currently not all files are available, and so end-to-end prediction is not possible with this code. As a result, for now, this repository presents only tools that can be leveraged in similar tasks.

## Task 1 - Prediction of patient age based on manipulated brain-scan latent features

- Rank 25/179
- Public-score: 0.750; Private-score: 0.713

Using neural networks unknown to us, features were extracted from brain-scan images. Additionaly, noise was added to certain datapoints, some features were duplicated, some useless features were added, and some elements of data points were entirely removed. The chritical pre-processing tasks were imputation and feature selection.

### Code
<details><summary>Expand</summary>
    
- __imputer_gridsearch.py__: A framework to compare imputation strategies. CatBoostRegressor was used to evalutate the resulting data.
- __model_gridsearch.py__: A framework to select the most optimal model hyperparameters. Framework is set-up to split the search up into multiple runs. Necessary due to the magnitude of the search. In its current state, the function is set-up to search for XGBoost hyperparameters, however, the same framework can be used for any scikit-learn-compatible model.

- __smart_stacking__: Stacking is computationaly demanding. To stack two models (base models), each model needs to be trained on the training data, via cross-val-predict, the models need to be trained k times on k-folds of the data, and finally a final linear regressor must be trained. In our approach, we present a framework in which these base models only need to be trained (once on the entire training data and k times on the folds) only one time, and then can be to on combination with an arbitratry number of models in stacking also trained in this manner. Finally, we also present a strategy to be able to cross-validate stacked combinations of models without having to retrain them.
    <details><summary>get_model_data.py</summary> Framework generates and saves models trained on entire training data, and on k folds of training data. Additionaly, cross validation predictions are saved for each fold. </details>
    <details><summary>smart_stacking.py</summary> Code combines what is generated by "get_model_data.py", trains some linear regressor to combine the cross-val predictions of various models, and then generates final predictions based on the predictions of models trained on entire training set. </details>
    
    <details><summary>get_cv_data.py</summary> Similar to "get_model_data.py", except it performs the same staps on another set of folds used for cross-validation. I.e. for m folds used for cross-val, we need models trained on the the entire dataset of each fold, and additionaly models trained and their corresponding cross-val-predictions on another k-folds of the data on each of the m-folds. </details>
    
    <details><summary>stacking_cv.py</summary> Like "smart_stacking.py", this code combines outcomes of "get_cv_data.py" to evalutate cross validation scores of various stacking combinations.</details>
    
    <details><summary>tools.py</summary> Presents a function through which a part of our code is parallelized. Simply in order to speed up training for cross validation predictions.</details>
</details>

## Task 2 - Classifification of raw ECG data
- Rank 3/168
- Public-score: 0.858; Private-score: 0.856

Given raw ECG data, our task was to classify data between 4 classes. These classes were imbalanced. Our stages of data processing were the following: idintifying and inverting inverted signals (generated due to misplacement of electrodes), extracting heartbeat templates, corresponding local hertbeat frequencies and QRS locations. To make our predictions, from the original signals and from this extracted information, we extracted features on which we trained boosted models. 

The feature extracted are seperated into three categories:
- Signal features: general features that can be extracted from any signal
- Expert features: ECG specific features
- Learned features: features extracted via a neural network framework. 

In this repository, only the third approach is currently available, and so the same accuracies can not be accomplished with this code alone.

After features are extracted, all features are combined, after which we perform feature extraction and final train a model to make predictions.

### Code
<details><summary>Expand</summary> 
    
- __ExtendedNet.py__: In this file, the neural network class "ExtendedNet" is available. This neural network takes the entire ECG sequence, of an arbitrary length and generates one feature vector. This network was trained by applying an additional linear layer at the end to perform the classification. The Neural Netowrk architecture consists of a residual, bottle-neck 1D-convolutional architecture, which outputs a seuqence with a reduced lenght but higher dimensionality, followed by a bi-directional LSTM and a deep fully-connected block.
- __ShortNet.py__: Using this architecture, we were not able to generate meaningful features. Further research would need to be done to leverege this architecture. The code consists of a lot of uncommented code, representing different strategies. The different strategies are the following. Apply LSTM layer on individual heartbeat templates to extract heartbeat features; then pass the resulting sequence of these heartbeat features through some final LSTM architecture. Different architectures were tried out. Alternatively we tried to leverage expert heartbeat features and then pass those through the final LSTM block.
- __train.py__: A function which guides the training of "ExtendedNet"
</detials>

